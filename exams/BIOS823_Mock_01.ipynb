{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIOS 823\n",
    "\n",
    "- The time allocated is 2 hours\n",
    "- This is a **closed book** examination\n",
    "    - Close ALL applications on your laptop\n",
    "    - Start an empty browser with a SINGLE Tab in FULL SCREEN MODE\n",
    "    - You should only have this SINGLE notebook page open in your browser, with NO OTHER TABS or WINDOWS\n",
    "- You are not allowed any reference material except for the following:\n",
    "    - Cheat sheet (1 letter-sized paper, both sides)\n",
    "    - Built-in help accessible either by `?foo`, `foo?` or `help(foo)`\n",
    "- ALL necessary imports of Python modules have been done for you. \n",
    "- **You should not import any additional modules - this includes standard library packages**.\n",
    "\n",
    "Note that answers will be graded on **correctness**, **efficiency** and **readability**.\n",
    "\n",
    "<font color=blue>By taking this exam, you acknowledge that you have read the instructions and agree to abide by the Duke Honor Code.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1**. (10 points)\n",
    "\n",
    "Warm up exercise.\n",
    "\n",
    "Find the 5 most common words and their counts in `data/moby.txt`, after removing punctuation, setting to lowercase and splitting by blank space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2**. (10 points)\n",
    "\n",
    "- Assemble the data from `features`, `subjects`, `X`, and `y` into a single `pandas.DataFrame (DF)` called `har`.  You should end up with a DF that is 7352 by 562 with `activity` as the first column. Rows and columns should be appropriately labeled.\n",
    "    - `X` is a matrix where each row is a feature matrix\n",
    "    - The columns of X are given in `features`\n",
    "    - Each row of X is a subject given in `subjects`\n",
    "    - `y` is a code for the type of activity performed by the subject (name the column in the DataFrame `actvitity`)\n",
    "- Name the index `subject`\n",
    "- Display a sample of 5 rows chosen at random without replacement and the first 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = np.loadtxt('data/HAR/activity_labels.txt', dtype='str')\n",
    "features = np.loadtxt('data/HAR/features.txt', dtype='str')[:, 1]\n",
    "subjects = np.loadtxt('data/HAR/train/subject_train.txt', dtype='int')\n",
    "X = np.loadtxt('data/HAR/train/X_train.txt')\n",
    "y = np.loadtxt('data/HAR/train/y_train.txt', dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**. (10 points)\n",
    "\n",
    "Using the DF from Question 1, find the average feature value for each subject for all features that have the string `entropy` in it but does NOT end in X, Y or Z. Use method chaining to perform this operation and show a random sample of 5 rows without replacement as a single expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4**. (10 points)\n",
    "\n",
    "Write an SQL query against the `har` table to count the number of distinct subjects and the total number of rows for each activity, ordering the results by number of rows for each activity in decreasing order. A simple example of how to run an SQL query using `pandas` is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///data/har.db', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT subject, activity \n",
    "FROM har \n",
    "LIMIT 5\n",
    "'''\n",
    "pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5**. (25 points)\n",
    "\n",
    "- Create a new DF `df` from the `har` DF with all features that include the string `Acc-mean`\n",
    "- Scale the feature columns so that all features have mean 0 and standard deviation 1\n",
    "- Use SVD to find the first two principal components\n",
    "- Plot the first two principal components as a scatter plot colored by the `activity` type of each feature vector\n",
    "- Plot the 2D t-SNE plot colored in the same way (t-SNE dimension reduction may take 1-2 minutes)\n",
    "\n",
    "Do not import any other packages apart from the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = np.loadtxt('data/HAR/test/X_test.txt')\n",
    "y_test_data = np.loadtxt('data/HAR/test/y_test.txt', dtype='int')\n",
    "subjects_test = np.loadtxt('data/HAR/test/subject_test.txt', dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6**. (25 points)\n",
    "\n",
    "You are given training and test data and labels using a subset of the HAR data set. Your job is to use these features to classify rows into WALKING UPSTAIRS (code = 2) or WALKING DOWNSTAIRS (code = 3). \n",
    "\n",
    "- Scale the data to have mean zero and unit standard deviation using `StandardScaler`, taking care to apply the same scaling parameters for the training and test data sets\n",
    "- Use the LaeblEncoder to transform the codes 2 and 3 to 0 and 1 in `y_train` and `y_test` \n",
    "- Perform ridge regression to classify data as WALKING UPSTAIRS or WALKING DOWNSTAIRS\n",
    "    - Train the model with an Cs value chosen from one of (0.01, 0.1, 1, 10, 100) by 5-fold cross-validation using the training data\n",
    "    - Plot the ROC curve (TPR versus FPR) evaluated on the test data\n",
    "\n",
    "The necessary classes from `sklearn` are imported for you. Do not use any other `sklearn` classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/X_train.npy')\n",
    "X_test = np.load('data/X_test.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "y_test = np.load('data/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
