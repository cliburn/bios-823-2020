{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project instructions\n",
    "\n",
    "Final projects are due by **9 AM 20 Nov, 2020**.\n",
    "\n",
    "### Timeline\n",
    "\n",
    "**Note**: You are free to revise *any* of the entries below, so don't be constrained by what you wrote if it does not work out. For example, you might change the data science objective, change the technology stack used, etc - if doing so would improve the project outcome.\n",
    "\n",
    "The dates given below are guides, but evidence of regular, incremental progress on the project will be considered in the final grade.\n",
    "\n",
    "Aim to complete the first draft of the project by **05 Nov 2020**. Each group will be asked to make class presentations on their project between 05-20 Nov 2020.\n",
    "\n",
    "#### By 11 Sep 2020\n",
    "\n",
    "- Form a team\n",
    "    - Give your team a name\n",
    "    - Form a team GitHub repository for your project \n",
    "        - you will write your own blog about the project on your individual GitHub-pages, but refer to the group repository for project content\n",
    "    - List members of your team and program on the README page\n",
    "    - Send Cliburn and Michale the following information:\n",
    "        - URL of team GitHUb repository\n",
    "        - Team name\n",
    "        - Name, email and program of each team member\n",
    "        - Which of the 3 data sets you will be working on\n",
    "    - Set up a channel for team communication on Teams/Slack\n",
    "    - Set up schedule for team meetings\n",
    "          \n",
    "#### By 25 Sep 2020\n",
    "\n",
    "- The team repository README should contain the following\n",
    "    - The specific data sets you will be working with\n",
    "    - The objective of the project and how it benefits the target consumer\n",
    "        - What is the data product(s) that will be generated? For example, the project can generate one or more of the following\n",
    "            - Report (e.g. auto-generated PDF)\n",
    "            - Dashboard\n",
    "            - Online ML algorithm\n",
    "            - App\n",
    "            - Other\n",
    "    - A sketch of the data science plan, which may include (if appropriate)\n",
    "        - Data plan (Extract, Load, Transform)\n",
    "        - ML plan (Model training, evaluation, selection, deployment, monitoring)\n",
    "        - Operations plan (workflow orchestration, CI/CD, containerization, serverless, testing, packaging, logging)\n",
    "        - Technology stack (databases, python packages, cloud platform)\n",
    "    - Roles, responsibilities and *timed milestones* for each team member\n",
    "        - Plan for *accountability* but be willing to help out team members\n",
    "        - Ask team members for help if you are overwhelmed\n",
    "    - Set up channels for cross-team experts on Teams/Slack\n",
    "        - Channel for **data engineering**\n",
    "            - Databases (SQL, NoSQL)\n",
    "            - ELT (`singer`)\n",
    "            - Distributed data (`spark`)\n",
    "            - Workflow orchestration (`airflow`)_\n",
    "        - Channel for **data science and ML**\n",
    "            - EDA and visualization (`pandas`, `vaex`)\n",
    "            - Dashboards (`dash`, `streamlit`)\n",
    "            - ML frameworks (`scikit-learn`, `tensorflow`)\n",
    "            - Explainability (`yellowbrick`, `shap`)\n",
    "        - Channel for **operations**\n",
    "            - Testing (`pytest`)\n",
    "            - Containers (`docker`, `docker-compose`, `kubernetes`)\n",
    "            - CI/CD (`jenkins`, `buddy`, `CircleCI`)\n",
    "            - Cloud platforms (`aws`, `gcp`, `azure`)\n",
    "\n",
    "        \n",
    "####  25 Sep  - 05 Nov 2020\n",
    "\n",
    "- Do the research and necessary work as planned\n",
    "- Perform a branch and merge operation to fix a bug or add a feature\n",
    "- Contribute something to another team's project by forking and submitting a pull request\n",
    "\n",
    "#### 05 Nov - 20 Nov\n",
    "\n",
    "- Generate and review data product\n",
    "- Final optimizations\n",
    "- Revise team project README page\n",
    "- Write personal blog\n",
    "- Prepare for class presentation\n",
    "\n",
    "#### 20 Nov 2020\n",
    "\n",
    "- Final project due"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to see how much time you have left!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 2 months before proejct submission deadline.\n"
     ]
    }
   ],
   "source": [
    "import pendulum\n",
    "\n",
    "deadline = pendulum.datetime(2020, 11, 20, 9, 0, 0,tz='US/Eastern')\n",
    "print(f'You have {pendulum.now().diff_for_humans(deadline)} proejct submission deadline.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project instructions\n",
    "\n",
    "For the final project, you will choose a data set(s) from the following topics\n",
    "\n",
    "- COVID-19\n",
    "- ICU admission\n",
    "- Brain imaging\n",
    "\n",
    "From a team of 3-4 people. Each team will need to do the following:\n",
    "\n",
    "- Identify and frame data science problem to solve given the data (data analyst/domain expert)\n",
    "- Process and manage the data so that it is easily accessible (data engineer)\n",
    "- Develop the analysis, modeling and reporting data product (data scientist / machine learning engineer)\n",
    "\n",
    "Each group member will also have to do the following *individual* task:\n",
    "\n",
    "- Write a post on GitHub-pages about the project and what you learned from doing this\n",
    "\n",
    "**Note**: 80% of the grade will be based on the quality of the project as a whole (team effort); 20% will be based on teh quality of the blog/report (individual effort).\n",
    "\n",
    "### You should use the project to showcase the following skill sets\n",
    "\n",
    "- Basic skills\n",
    "    - Effective use of version control\n",
    "        - Ideally, showcase branch and merge skills for concurrent feature development / bug fixes\n",
    "    - Literate programming\n",
    "    - Functional coding style\n",
    "- Domain knowledge\n",
    "    - Introduction of domain concepts necessary to understand the data set(s)\n",
    "    - Framing the data science challenge\n",
    "- Data management\n",
    "    - Use of different data formats\n",
    "    - Use of SQL and/or NoSQL databases\n",
    "- Data analysis and visualization\n",
    "    - Data cleaning and validation\n",
    "    - Use of linked data sources if applicable\n",
    "    - Attractive and easy-to-understand reports and/or dashboards\n",
    "- Development of data product\n",
    "    - This is often a predictive machine learning model (classical or deep)\n",
    "        - Construct pipeline, perform model training, evaluation and selection\n",
    "    - Other data products can also be developed (in place of or in addition to supervised learning) if more appropriate for your problem\n",
    "        - Examples - unsupervised or self-supervised models, graphical models, complex interactive visualizations\n",
    "- Operationalization\n",
    "    - Testing, logging, monitoring, streaming, packaging if applicable\n",
    "    - Use of distributed computing platform if applicable\n",
    "    - Deployment to cloud platform (including serverless if applicable)\n",
    "    \n",
    "### Milestones\n",
    "\n",
    "- Form team (diversity is essential - teams **must** consist of people from at least 2 different programs)\n",
    "- Initial exploration of data sets for all topics\n",
    "- Choose topic\n",
    "- Further exploration of data sets for selected topic\n",
    "- Frame data science problem to solve\n",
    "- Develop the data science and machine learning product\n",
    "- Deploy the product to a cloud platform (GCP, Azure, AWS)\n",
    "- Streamline and automate \n",
    "\n",
    "\n",
    "### Suggestions for working as a team\n",
    "\n",
    "- You should begin as soon as possible\n",
    "- Aim to have a group meeting at least 1-2 times a week\n",
    "- Set up Teams or Slack for communication within your team\n",
    "- Probably easiest if someone takes the role of project manager to \n",
    "    - coordinate group activities \n",
    "    - check that sufficient progress is being made week-by-week.\n",
    "- Avoid excessive \"divide and conquer\" specialization\n",
    "    - individual should take on at least two roles\n",
    "    - each skill set area should have at least two people involved\n",
    "    - teach your team members how you performed a task that not everyone is familiar with\n",
    "\n",
    "## Data resources\n",
    "\n",
    "Your primary data source should be from one of these three links provided. You can, however, link to other public reference data sets, databases or ontologies if appropriate.\n",
    "\n",
    "**Notes** \n",
    "\n",
    "- To access the data set, you may need to register on the site, or even complete specified training courses.\n",
    "- If you need the data sets put on the Duke Spark cluster, please let me know and we will work with OIT to make this possible\n",
    "\n",
    "### Open-Access Data and Computational Resources to Address COVID-19 [link](https://datascience.nih.gov/covid-19-open-access-resources)\n",
    "\n",
    "- COVID-19 open-access data and computational resources are being provided by federal agencies, including NIH, public consortia, and private entities. These resources are freely available to researchers, and this page will be updated as more information becomes available. \n",
    "- The Office of Data Science Strategy seeks to provide the research community with links to open-access data, computational, and supporting resources. These resources are being aggregated and posted for scientific and public health interests. Inclusion of a resource on this list does not mean it has been evaluated or endorsed by NIH.\n",
    "\n",
    "### MIMIC [link](https://mimic.physionet.org)\n",
    "\n",
    "- Deidentified health data associated with ~60,000 ICU admissions (53,432 adult patients and 8,100 neonatal patients) from June 2001 to October 2012\n",
    "- Includes demographics, vital signs, laboratory tests, medications, and more\n",
    "\n",
    "\n",
    "### Oasis Brains Project [link](http://www.oasis-brains.org/)\n",
    "\n",
    "- Neuroimaging datasets; have been utilized for hypothesis driven data analyses, development of neuroanatomical atlases, and development of segmentation algorithms\n",
    "- OASIS-1: Cross-sectional MRI data in young, middle aged, nondemented and demented older adults\n",
    "o\t416 subjects; 434 MRI sessions\n",
    "- OASIS-2: Longitudinal MRI data in nondemented and demented older adults\n",
    "o\t150 subjects; 373 MRI sessions\n",
    "- OASIS-3: Longitudinal neuroimaging, clinical, and cognitive dataset for normal aging and Alzheimerâ€™s disease\n",
    "o\t1098 subjects; 2168 MRI sessions; 1608 PET sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
